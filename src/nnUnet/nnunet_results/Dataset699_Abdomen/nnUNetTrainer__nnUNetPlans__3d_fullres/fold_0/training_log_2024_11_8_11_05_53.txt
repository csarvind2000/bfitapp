
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-11-08 11:05:53.531296: do_dummy_2d_data_aug: True 
2024-11-08 11:05:53.532035: Creating new 5-fold cross-validation split... 
2024-11-08 11:05:53.533546: Desired fold for training: 0 
2024-11-08 11:05:53.533611: This split has 84 training and 21 validation cases. 
2024-11-08 11:05:56.880687: Using torch.compile... 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [48, 224, 224], 'median_image_size_in_voxels': [56.0, 254.0, 255.0], 'spacing': [3.0, 1.5625, 1.5625], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset699_AbdomenMR', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 1.5625, 1.5625], 'original_median_shape_after_transp': [42, 254, 256], 'image_reader_writer': 'NibabelIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 4439.0, 'mean': 518.4749145507812, 'median': 498.0, 'min': -2.0, 'percentile_00_5': 102.0, 'percentile_99_5': 1559.0, 'std': 237.89584350585938}}} 
 
2024-11-08 11:05:56.885848: unpacking dataset... 
2024-11-08 11:06:04.813469: unpacking done... 
2024-11-08 11:06:04.816125: Unable to plot network architecture: nnUNet_compile is enabled! 
2024-11-08 11:06:04.825550:  
2024-11-08 11:06:04.825678: Epoch 0 
2024-11-08 11:06:04.826024: Current learning rate: 0.01 
2024-11-08 11:14:03.160501: train_loss -0.3002 
2024-11-08 11:14:03.160952: val_loss -0.6476 
2024-11-08 11:14:03.161110: Pseudo dice [np.float32(0.8516), np.float32(0.8075), np.float32(0.8908)] 
2024-11-08 11:14:03.161383: Epoch time: 478.34 s 
2024-11-08 11:14:03.161473: Yayy! New best EMA pseudo Dice: 0.8500000238418579 
2024-11-08 11:14:04.744465:  
2024-11-08 11:14:04.744681: Epoch 1 
2024-11-08 11:14:04.744904: Current learning rate: 0.00985 
2024-11-08 11:20:07.832459: train_loss -0.6819 
2024-11-08 11:20:07.832791: val_loss -0.7256 
2024-11-08 11:20:07.832917: Pseudo dice [np.float32(0.8808), np.float32(0.8526), np.float32(0.8968)] 
2024-11-08 11:20:07.833138: Epoch time: 363.09 s 
2024-11-08 11:20:07.833312: Yayy! New best EMA pseudo Dice: 0.8525999784469604 
2024-11-08 11:20:11.390006:  
2024-11-08 11:20:11.390403: Epoch 2 
2024-11-08 11:20:11.390682: Current learning rate: 0.0097 
2024-11-08 11:26:12.734722: train_loss -0.7189 
2024-11-08 11:26:12.735166: val_loss -0.7376 
2024-11-08 11:26:12.735306: Pseudo dice [np.float32(0.8857), np.float32(0.8579), np.float32(0.9194)] 
2024-11-08 11:26:12.735430: Epoch time: 361.35 s 
2024-11-08 11:26:12.735551: Yayy! New best EMA pseudo Dice: 0.8561000227928162 
2024-11-08 11:26:16.324131:  
2024-11-08 11:26:16.324269: Epoch 3 
2024-11-08 11:26:16.324481: Current learning rate: 0.00955 
2024-11-08 11:32:17.759248: train_loss -0.7535 
2024-11-08 11:32:17.759697: val_loss -0.7754 
2024-11-08 11:32:17.759909: Pseudo dice [np.float32(0.8983), np.float32(0.8647), np.float32(0.9317)] 
2024-11-08 11:32:17.760055: Epoch time: 361.44 s 
2024-11-08 11:32:17.760139: Yayy! New best EMA pseudo Dice: 0.8603000044822693 
2024-11-08 11:32:21.848334:  
2024-11-08 11:32:21.848711: Epoch 4 
2024-11-08 11:32:21.848864: Current learning rate: 0.0094 
2024-11-08 11:38:24.723695: train_loss -0.7538 
2024-11-08 11:38:24.724135: val_loss -0.773 
2024-11-08 11:38:24.724312: Pseudo dice [np.float32(0.8999), np.float32(0.8761), np.float32(0.9248)] 
2024-11-08 11:38:24.724484: Epoch time: 362.88 s 
2024-11-08 11:38:24.724595: Yayy! New best EMA pseudo Dice: 0.864300012588501 
2024-11-08 11:38:28.343812:  
2024-11-08 11:38:28.344311: Epoch 5 
2024-11-08 11:38:28.344506: Current learning rate: 0.00925 
2024-11-08 11:44:29.676516: train_loss -0.7705 
2024-11-08 11:44:29.676995: val_loss -0.79 
2024-11-08 11:44:29.677141: Pseudo dice [np.float32(0.8987), np.float32(0.8782), np.float32(0.9327)] 
2024-11-08 11:44:29.677273: Epoch time: 361.33 s 
2024-11-08 11:44:29.677369: Yayy! New best EMA pseudo Dice: 0.8682000041007996 
2024-11-08 11:44:33.103216:  
2024-11-08 11:44:33.103539: Epoch 6 
2024-11-08 11:44:33.103758: Current learning rate: 0.0091 
2024-11-08 11:50:34.558587: train_loss -0.7776 
2024-11-08 11:50:34.559160: val_loss -0.8058 
2024-11-08 11:50:34.559337: Pseudo dice [np.float32(0.9116), np.float32(0.8878), np.float32(0.9353)] 
2024-11-08 11:50:34.559453: Epoch time: 361.46 s 
2024-11-08 11:50:34.559549: Yayy! New best EMA pseudo Dice: 0.8726000189781189 
2024-11-08 11:50:38.091729:  
2024-11-08 11:50:38.092031: Epoch 7 
2024-11-08 11:50:38.092239: Current learning rate: 0.00894 
2024-11-08 11:56:48.582964: train_loss -0.7762 
2024-11-08 11:56:48.583262: val_loss -0.7934 
2024-11-08 11:56:48.583478: Pseudo dice [np.float32(0.9057), np.float32(0.8874), np.float32(0.9337)] 
2024-11-08 11:56:48.583586: Epoch time: 370.49 s 
2024-11-08 11:56:48.583662: Yayy! New best EMA pseudo Dice: 0.8762000203132629 
2024-11-08 11:56:52.111275:  
2024-11-08 11:56:52.111558: Epoch 8 
2024-11-08 11:56:52.111796: Current learning rate: 0.00879 
2024-11-08 12:03:02.389858: train_loss -0.7817 
2024-11-08 12:03:02.390063: val_loss -0.8064 
2024-11-08 12:03:02.390160: Pseudo dice [np.float32(0.9142), np.float32(0.8807), np.float32(0.9344)] 
2024-11-08 12:03:02.390286: Epoch time: 370.28 s 
2024-11-08 12:03:02.390366: Yayy! New best EMA pseudo Dice: 0.8794999718666077 
2024-11-08 12:03:05.794121:  
2024-11-08 12:03:05.794497: Epoch 9 
2024-11-08 12:03:05.794648: Current learning rate: 0.00864 
2024-11-08 12:09:14.295640: train_loss -0.7874 
2024-11-08 12:09:14.295981: val_loss -0.8131 
2024-11-08 12:09:14.296139: Pseudo dice [np.float32(0.9154), np.float32(0.8915), np.float32(0.9372)] 
2024-11-08 12:09:14.296280: Epoch time: 368.5 s 
2024-11-08 12:09:14.296455: Yayy! New best EMA pseudo Dice: 0.8830999732017517 
2024-11-08 12:09:18.002258:  
2024-11-08 12:09:18.002531: Epoch 10 
2024-11-08 12:09:18.002712: Current learning rate: 0.00849 
2024-11-08 12:15:27.815922: train_loss -0.7984 
2024-11-08 12:15:27.816298: val_loss -0.8095 
2024-11-08 12:15:27.816473: Pseudo dice [np.float32(0.9146), np.float32(0.8922), np.float32(0.9311)] 
2024-11-08 12:15:27.816594: Epoch time: 369.81 s 
2024-11-08 12:15:27.816677: Yayy! New best EMA pseudo Dice: 0.8859999775886536 
2024-11-08 12:15:31.435835:  
2024-11-08 12:15:31.436077: Epoch 11 
2024-11-08 12:15:31.436442: Current learning rate: 0.00833 
2024-11-08 12:21:43.922480: train_loss -0.8031 
2024-11-08 12:21:43.922858: val_loss -0.8223 
2024-11-08 12:21:43.922972: Pseudo dice [np.float32(0.9181), np.float32(0.8935), np.float32(0.9388)] 
2024-11-08 12:21:43.923093: Epoch time: 372.49 s 
2024-11-08 12:21:43.923193: Yayy! New best EMA pseudo Dice: 0.8891000151634216 
2024-11-08 12:21:47.558106:  
2024-11-08 12:21:47.558416: Epoch 12 
2024-11-08 12:21:47.558585: Current learning rate: 0.00818 
2024-11-08 12:28:02.523280: train_loss -0.8049 
2024-11-08 12:28:02.523779: val_loss -0.8295 
2024-11-08 12:28:02.523887: Pseudo dice [np.float32(0.9235), np.float32(0.8985), np.float32(0.9417)] 
2024-11-08 12:28:02.524037: Epoch time: 374.97 s 
2024-11-08 12:28:02.524121: Yayy! New best EMA pseudo Dice: 0.892300009727478 
2024-11-08 12:28:06.144185:  
2024-11-08 12:28:06.144516: Epoch 13 
2024-11-08 12:28:06.144690: Current learning rate: 0.00803 
2024-11-08 12:34:15.565791: train_loss -0.8062 
2024-11-08 12:34:15.566056: val_loss -0.8081 
2024-11-08 12:34:15.566168: Pseudo dice [np.float32(0.9139), np.float32(0.8865), np.float32(0.933)] 
2024-11-08 12:34:15.566372: Epoch time: 369.42 s 
2024-11-08 12:34:15.566519: Yayy! New best EMA pseudo Dice: 0.8942000269889832 
2024-11-08 12:34:19.114780:  
2024-11-08 12:34:19.115180: Epoch 14 
2024-11-08 12:34:19.115379: Current learning rate: 0.00787 
2024-11-08 12:40:27.621493: train_loss -0.7963 
2024-11-08 12:40:27.621819: val_loss -0.8217 
2024-11-08 12:40:27.621926: Pseudo dice [np.float32(0.9169), np.float32(0.8924), np.float32(0.9377)] 
2024-11-08 12:40:27.622044: Epoch time: 368.51 s 
2024-11-08 12:40:27.622371: Yayy! New best EMA pseudo Dice: 0.8963000178337097 
2024-11-08 12:40:31.217374:  
2024-11-08 12:40:31.217720: Epoch 15 
2024-11-08 12:40:31.217868: Current learning rate: 0.00772 
2024-11-08 12:46:39.400646: train_loss -0.8029 
2024-11-08 12:46:39.401054: val_loss -0.8267 
2024-11-08 12:46:39.401179: Pseudo dice [np.float32(0.9194), np.float32(0.8987), np.float32(0.9401)] 
2024-11-08 12:46:39.401349: Epoch time: 368.18 s 
2024-11-08 12:46:39.401436: Yayy! New best EMA pseudo Dice: 0.8985999822616577 
2024-11-08 12:46:43.174602:  
2024-11-08 12:46:43.174743: Epoch 16 
2024-11-08 12:46:43.174913: Current learning rate: 0.00756 
2024-11-08 12:53:03.552275: train_loss -0.813 
2024-11-08 12:53:03.552771: val_loss -0.8314 
2024-11-08 12:53:03.552901: Pseudo dice [np.float32(0.9218), np.float32(0.9001), np.float32(0.9421)] 
2024-11-08 12:53:03.553054: Epoch time: 380.38 s 
2024-11-08 12:53:03.553145: Yayy! New best EMA pseudo Dice: 0.9009000062942505 
2024-11-08 12:53:07.504525:  
2024-11-08 12:53:07.504829: Epoch 17 
2024-11-08 12:53:07.505012: Current learning rate: 0.00741 
2024-11-08 12:59:18.984799: train_loss -0.8147 
2024-11-08 12:59:18.985158: val_loss -0.8301 
2024-11-08 12:59:18.985346: Pseudo dice [np.float32(0.9192), np.float32(0.906), np.float32(0.9388)] 
2024-11-08 12:59:18.985484: Epoch time: 371.48 s 
2024-11-08 12:59:18.985606: Yayy! New best EMA pseudo Dice: 0.902999997138977 
2024-11-08 12:59:22.619103:  
2024-11-08 12:59:22.619516: Epoch 18 
2024-11-08 12:59:22.619733: Current learning rate: 0.00725 
2024-11-08 13:05:33.508784: train_loss -0.8189 
2024-11-08 13:05:33.509115: val_loss -0.8337 
2024-11-08 13:05:33.509302: Pseudo dice [np.float32(0.9255), np.float32(0.9005), np.float32(0.9393)] 
2024-11-08 13:05:33.509439: Epoch time: 370.89 s 
2024-11-08 13:05:33.509529: Yayy! New best EMA pseudo Dice: 0.9047999978065491 
2024-11-08 13:05:37.192845:  
2024-11-08 13:05:37.193059: Epoch 19 
2024-11-08 13:05:37.193235: Current learning rate: 0.0071 
2024-11-08 13:11:46.905552: train_loss -0.8192 
2024-11-08 13:11:46.905995: val_loss -0.8325 
2024-11-08 13:11:46.906107: Pseudo dice [np.float32(0.925), np.float32(0.8993), np.float32(0.9421)] 
2024-11-08 13:11:46.906245: Epoch time: 369.71 s 
2024-11-08 13:11:46.906356: Yayy! New best EMA pseudo Dice: 0.9065999984741211 
2024-11-08 13:11:50.639488:  
2024-11-08 13:11:50.639812: Epoch 20 
2024-11-08 13:11:50.640008: Current learning rate: 0.00694 
2024-11-08 13:18:00.650810: train_loss -0.8207 
2024-11-08 13:18:00.651037: val_loss -0.8383 
2024-11-08 13:18:00.651156: Pseudo dice [np.float32(0.9249), np.float32(0.8977), np.float32(0.9447)] 
2024-11-08 13:18:00.651296: Epoch time: 370.01 s 
2024-11-08 13:18:00.651392: Yayy! New best EMA pseudo Dice: 0.9082000255584717 
2024-11-08 13:18:04.214421:  
2024-11-08 13:18:04.214788: Epoch 21 
2024-11-08 13:18:04.214969: Current learning rate: 0.00679 
2024-11-08 13:24:12.482610: train_loss -0.8232 
2024-11-08 13:24:12.482958: val_loss -0.8388 
2024-11-08 13:24:12.483082: Pseudo dice [np.float32(0.9248), np.float32(0.9024), np.float32(0.9428)] 
2024-11-08 13:24:12.483263: Epoch time: 368.27 s 
2024-11-08 13:24:12.483597: Yayy! New best EMA pseudo Dice: 0.9096999764442444 
2024-11-08 13:24:16.077360:  
2024-11-08 13:24:16.077671: Epoch 22 
2024-11-08 13:24:16.077911: Current learning rate: 0.00663 
2024-11-08 13:30:26.669998: train_loss -0.8198 
2024-11-08 13:30:26.670306: val_loss -0.8428 
2024-11-08 13:30:26.670473: Pseudo dice [np.float32(0.9285), np.float32(0.9087), np.float32(0.9425)] 
2024-11-08 13:30:26.670634: Epoch time: 370.59 s 
2024-11-08 13:30:26.670738: Yayy! New best EMA pseudo Dice: 0.9114000201225281 
2024-11-08 13:30:30.506514:  
2024-11-08 13:30:30.506896: Epoch 23 
2024-11-08 13:30:30.507106: Current learning rate: 0.00647 
2024-11-08 13:36:34.066032: train_loss -0.8218 
2024-11-08 13:36:34.066594: val_loss -0.8417 
2024-11-08 13:36:34.066723: Pseudo dice [np.float32(0.9265), np.float32(0.9043), np.float32(0.9421)] 
2024-11-08 13:36:34.066853: Epoch time: 363.56 s 
2024-11-08 13:36:34.066952: Yayy! New best EMA pseudo Dice: 0.9126999974250793 
2024-11-08 13:36:37.682435:  
2024-11-08 13:36:37.682799: Epoch 24 
2024-11-08 13:36:37.682979: Current learning rate: 0.00631 
2024-11-08 13:42:37.642271: train_loss -0.822 
2024-11-08 13:42:37.642691: val_loss -0.8461 
2024-11-08 13:42:37.642842: Pseudo dice [np.float32(0.9296), np.float32(0.908), np.float32(0.9471)] 
2024-11-08 13:42:37.642979: Epoch time: 359.96 s 
2024-11-08 13:42:37.643080: Yayy! New best EMA pseudo Dice: 0.9142000079154968 
2024-11-08 13:42:41.569999:  
2024-11-08 13:42:41.570297: Epoch 25 
2024-11-08 13:42:41.570478: Current learning rate: 0.00616 
2024-11-08 13:48:41.886746: train_loss -0.8278 
2024-11-08 13:48:41.887579: val_loss -0.8464 
2024-11-08 13:48:41.887723: Pseudo dice [np.float32(0.931), np.float32(0.9051), np.float32(0.9441)] 
2024-11-08 13:48:41.887922: Epoch time: 360.32 s 
2024-11-08 13:48:41.888031: Yayy! New best EMA pseudo Dice: 0.9154999852180481 
2024-11-08 13:48:45.695407:  
2024-11-08 13:48:45.695786: Epoch 26 
2024-11-08 13:48:45.696000: Current learning rate: 0.006 
2024-11-08 13:54:46.831766: train_loss -0.8289 
2024-11-08 13:54:46.832136: val_loss -0.8438 
2024-11-08 13:54:46.832297: Pseudo dice [np.float32(0.9291), np.float32(0.9047), np.float32(0.9456)] 
2024-11-08 13:54:46.832476: Epoch time: 361.14 s 
2024-11-08 13:54:46.832680: Yayy! New best EMA pseudo Dice: 0.9165999889373779 
2024-11-08 13:54:50.526097:  
2024-11-08 13:54:50.526504: Epoch 27 
2024-11-08 13:54:50.526660: Current learning rate: 0.00584 
2024-11-08 14:00:49.341490: train_loss -0.8309 
2024-11-08 14:00:49.341809: val_loss -0.8478 
2024-11-08 14:00:49.341934: Pseudo dice [np.float32(0.9306), np.float32(0.9121), np.float32(0.9417)] 
2024-11-08 14:00:49.342264: Epoch time: 358.82 s 
2024-11-08 14:00:49.342370: Yayy! New best EMA pseudo Dice: 0.9176999926567078 
2024-11-08 14:00:52.996190:  
2024-11-08 14:00:52.996466: Epoch 28 
2024-11-08 14:00:52.996617: Current learning rate: 0.00568 
2024-11-08 14:06:51.910273: train_loss -0.8282 
2024-11-08 14:06:51.910676: val_loss -0.8483 
2024-11-08 14:06:51.910794: Pseudo dice [np.float32(0.9315), np.float32(0.9134), np.float32(0.9446)] 
2024-11-08 14:06:51.910951: Epoch time: 358.92 s 
2024-11-08 14:06:51.911128: Yayy! New best EMA pseudo Dice: 0.9189000129699707 
2024-11-08 14:06:55.571358:  
2024-11-08 14:06:55.571589: Epoch 29 
2024-11-08 14:06:55.571737: Current learning rate: 0.00552 
2024-11-08 14:12:55.884804: train_loss -0.8318 
2024-11-08 14:12:55.885298: val_loss -0.852 
2024-11-08 14:12:55.885515: Pseudo dice [np.float32(0.9339), np.float32(0.9102), np.float32(0.9506)] 
2024-11-08 14:12:55.885651: Epoch time: 360.31 s 
2024-11-08 14:12:55.885745: Yayy! New best EMA pseudo Dice: 0.920199990272522 
2024-11-08 14:12:59.993599:  
2024-11-08 14:12:59.993985: Epoch 30 
2024-11-08 14:12:59.994390: Current learning rate: 0.00536 
2024-11-08 14:19:00.059308: train_loss -0.8343 
2024-11-08 14:19:00.059670: val_loss -0.8479 
2024-11-08 14:19:00.059801: Pseudo dice [np.float32(0.9334), np.float32(0.907), np.float32(0.9454)] 
2024-11-08 14:19:00.059935: Epoch time: 360.07 s 
2024-11-08 14:19:00.060028: Yayy! New best EMA pseudo Dice: 0.9210000038146973 
2024-11-08 14:19:03.858522:  
2024-11-08 14:19:03.858960: Epoch 31 
2024-11-08 14:19:03.859249: Current learning rate: 0.0052 
2024-11-08 14:25:03.659725: train_loss -0.8328 
2024-11-08 14:25:03.661011: val_loss -0.8571 
2024-11-08 14:25:03.661232: Pseudo dice [np.float32(0.9355), np.float32(0.9167), np.float32(0.9507)] 
2024-11-08 14:25:03.661482: Epoch time: 359.8 s 
2024-11-08 14:25:03.661649: Yayy! New best EMA pseudo Dice: 0.9223999977111816 
2024-11-08 14:25:07.297525:  
2024-11-08 14:25:07.297933: Epoch 32 
2024-11-08 14:25:07.298093: Current learning rate: 0.00504 
2024-11-08 14:31:08.536083: train_loss -0.8398 
2024-11-08 14:31:08.536415: val_loss -0.8562 
2024-11-08 14:31:08.536544: Pseudo dice [np.float32(0.9344), np.float32(0.9172), np.float32(0.9445)] 
2024-11-08 14:31:08.536717: Epoch time: 361.24 s 
2024-11-08 14:31:08.536912: Yayy! New best EMA pseudo Dice: 0.92330002784729 
2024-11-08 14:31:12.079679:  
2024-11-08 14:31:12.080028: Epoch 33 
2024-11-08 14:31:12.080230: Current learning rate: 0.00487 
2024-11-08 14:37:13.097907: train_loss -0.8372 
2024-11-08 14:37:13.098249: val_loss -0.8547 
2024-11-08 14:37:13.098429: Pseudo dice [np.float32(0.9333), np.float32(0.9105), np.float32(0.949)] 
2024-11-08 14:37:13.098589: Epoch time: 361.02 s 
2024-11-08 14:37:13.098691: Yayy! New best EMA pseudo Dice: 0.9240999817848206 
2024-11-08 14:37:16.861645:  
2024-11-08 14:37:16.861980: Epoch 34 
2024-11-08 14:37:16.862155: Current learning rate: 0.00471 
2024-11-08 14:43:18.109791: train_loss -0.8327 
2024-11-08 14:43:18.110368: val_loss -0.8531 
2024-11-08 14:43:18.110519: Pseudo dice [np.float32(0.9324), np.float32(0.9127), np.float32(0.9457)] 
2024-11-08 14:43:18.110663: Epoch time: 361.25 s 
2024-11-08 14:43:18.110760: Yayy! New best EMA pseudo Dice: 0.9247000217437744 
2024-11-08 14:43:21.814413:  
2024-11-08 14:43:21.816187: Epoch 35 
2024-11-08 14:43:21.816846: Current learning rate: 0.00455 
2024-11-08 14:49:21.667572: train_loss -0.8392 
2024-11-08 14:49:21.668139: val_loss -0.8526 
2024-11-08 14:49:21.668263: Pseudo dice [np.float32(0.9337), np.float32(0.9145), np.float32(0.9471)] 
2024-11-08 14:49:21.668396: Epoch time: 359.86 s 
2024-11-08 14:49:21.668497: Yayy! New best EMA pseudo Dice: 0.9254000186920166 
2024-11-08 14:49:25.473616:  
2024-11-08 14:49:25.473998: Epoch 36 
2024-11-08 14:49:25.474236: Current learning rate: 0.00438 
2024-11-08 14:55:25.244063: train_loss -0.8361 
2024-11-08 14:55:25.244526: val_loss -0.8486 
2024-11-08 14:55:25.244678: Pseudo dice [np.float32(0.931), np.float32(0.9109), np.float32(0.9444)] 
2024-11-08 14:55:25.244810: Epoch time: 359.77 s 
2024-11-08 14:55:25.244897: Yayy! New best EMA pseudo Dice: 0.9258000254631042 
2024-11-08 14:55:29.377411:  
2024-11-08 14:55:29.377759: Epoch 37 
2024-11-08 14:55:29.377915: Current learning rate: 0.00422 
2024-11-08 15:01:29.767178: train_loss -0.8404 
2024-11-08 15:01:29.767622: val_loss -0.8564 
2024-11-08 15:01:29.767738: Pseudo dice [np.float32(0.9361), np.float32(0.9203), np.float32(0.9486)] 
2024-11-08 15:01:29.767857: Epoch time: 360.39 s 
2024-11-08 15:01:29.767985: Yayy! New best EMA pseudo Dice: 0.9266999959945679 
2024-11-08 15:01:33.461569:  
2024-11-08 15:01:33.461878: Epoch 38 
2024-11-08 15:01:33.462069: Current learning rate: 0.00405 
2024-11-08 15:07:35.162468: train_loss -0.8387 
2024-11-08 15:07:35.162820: val_loss -0.8551 
2024-11-08 15:07:35.162952: Pseudo dice [np.float32(0.9364), np.float32(0.9156), np.float32(0.9466)] 
2024-11-08 15:07:35.163086: Epoch time: 361.7 s 
2024-11-08 15:07:35.163328: Yayy! New best EMA pseudo Dice: 0.927299976348877 
2024-11-08 15:07:38.748069:  
2024-11-08 15:07:38.748456: Epoch 39 
2024-11-08 15:07:38.748638: Current learning rate: 0.00389 
2024-11-08 15:13:41.205503: train_loss -0.8381 
2024-11-08 15:13:41.205823: val_loss -0.859 
2024-11-08 15:13:41.205966: Pseudo dice [np.float32(0.9372), np.float32(0.9206), np.float32(0.948)] 
2024-11-08 15:13:41.206151: Epoch time: 362.46 s 
2024-11-08 15:13:41.206357: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2024-11-08 15:13:44.806270:  
2024-11-08 15:13:44.806563: Epoch 40 
2024-11-08 15:13:44.806789: Current learning rate: 0.00372 
2024-11-08 15:19:45.680795: train_loss -0.8376 
2024-11-08 15:19:45.681145: val_loss -0.8518 
2024-11-08 15:19:45.681362: Pseudo dice [np.float32(0.934), np.float32(0.916), np.float32(0.9423)] 
2024-11-08 15:19:45.681490: Epoch time: 360.88 s 
2024-11-08 15:19:45.681608: Yayy! New best EMA pseudo Dice: 0.9283999800682068 
2024-11-08 15:19:49.402489:  
2024-11-08 15:19:49.402914: Epoch 41 
2024-11-08 15:19:49.403104: Current learning rate: 0.00355 
2024-11-08 15:25:54.647547: train_loss -0.8384 
2024-11-08 15:25:54.647902: val_loss -0.8588 
2024-11-08 15:25:54.648031: Pseudo dice [np.float32(0.9353), np.float32(0.9132), np.float32(0.9505)] 
2024-11-08 15:25:54.648159: Epoch time: 365.25 s 
2024-11-08 15:25:54.648384: Yayy! New best EMA pseudo Dice: 0.9287999868392944 
2024-11-08 15:25:58.323723:  
2024-11-08 15:25:58.324171: Epoch 42 
2024-11-08 15:25:58.324356: Current learning rate: 0.00338 
2024-11-08 15:32:01.205518: train_loss -0.8408 
2024-11-08 15:32:01.206221: val_loss -0.8575 
2024-11-08 15:32:01.206413: Pseudo dice [np.float32(0.9373), np.float32(0.9139), np.float32(0.9485)] 
2024-11-08 15:32:01.206608: Epoch time: 362.88 s 
2024-11-08 15:32:01.206704: Yayy! New best EMA pseudo Dice: 0.9293000102043152 
2024-11-08 15:32:05.475997:  
2024-11-08 15:32:05.476408: Epoch 43 
2024-11-08 15:32:05.476621: Current learning rate: 0.00321 
2024-11-08 15:38:11.214845: train_loss -0.8453 
2024-11-08 15:38:11.215272: val_loss -0.8554 
2024-11-08 15:38:11.215387: Pseudo dice [np.float32(0.9361), np.float32(0.916), np.float32(0.9444)] 
2024-11-08 15:38:11.215507: Epoch time: 365.74 s 
2024-11-08 15:38:11.215592: Yayy! New best EMA pseudo Dice: 0.9296000003814697 
2024-11-08 15:38:14.929552:  
2024-11-08 15:38:14.929846: Epoch 44 
2024-11-08 15:38:14.929985: Current learning rate: 0.00304 
2024-11-08 15:44:17.492352: train_loss -0.8448 
2024-11-08 15:44:17.492644: val_loss -0.8609 
2024-11-08 15:44:17.492762: Pseudo dice [np.float32(0.9384), np.float32(0.9202), np.float32(0.948)] 
2024-11-08 15:44:17.492991: Epoch time: 362.56 s 
2024-11-08 15:44:17.493160: Yayy! New best EMA pseudo Dice: 0.9301999807357788 
2024-11-08 15:44:20.913975:  
2024-11-08 15:44:20.914320: Epoch 45 
2024-11-08 15:44:20.914504: Current learning rate: 0.00287 
2024-11-08 15:50:20.951559: train_loss -0.8449 
2024-11-08 15:50:20.951918: val_loss -0.8641 
2024-11-08 15:50:20.952244: Pseudo dice [np.float32(0.9376), np.float32(0.9264), np.float32(0.9493)] 
2024-11-08 15:50:20.952410: Epoch time: 360.04 s 
2024-11-08 15:50:20.952508: Yayy! New best EMA pseudo Dice: 0.930899977684021 
2024-11-08 15:50:24.656647:  
2024-11-08 15:50:24.657027: Epoch 46 
2024-11-08 15:50:24.657179: Current learning rate: 0.0027 
2024-11-08 15:56:24.594445: train_loss -0.8426 
2024-11-08 15:56:24.595156: val_loss -0.862 
2024-11-08 15:56:24.595360: Pseudo dice [np.float32(0.9376), np.float32(0.9178), np.float32(0.9456)] 
2024-11-08 15:56:24.595551: Epoch time: 359.94 s 
2024-11-08 15:56:24.595660: Yayy! New best EMA pseudo Dice: 0.9312000274658203 
2024-11-08 15:56:28.229298:  
2024-11-08 15:56:28.229594: Epoch 47 
2024-11-08 15:56:28.229849: Current learning rate: 0.00252 
2024-11-08 16:02:28.184341: train_loss -0.8409 
2024-11-08 16:02:28.184829: val_loss -0.8567 
2024-11-08 16:02:28.185065: Pseudo dice [np.float32(0.9371), np.float32(0.9139), np.float32(0.95)] 
2024-11-08 16:02:28.185282: Epoch time: 359.96 s 
2024-11-08 16:02:28.185377: Yayy! New best EMA pseudo Dice: 0.9314000010490417 
2024-11-08 16:02:31.669310:  
2024-11-08 16:02:31.669842: Epoch 48 
2024-11-08 16:02:31.670037: Current learning rate: 0.00235 
2024-11-08 16:08:31.057687: train_loss -0.8442 
2024-11-08 16:08:31.058152: val_loss -0.8604 
2024-11-08 16:08:31.058288: Pseudo dice [np.float32(0.9374), np.float32(0.9198), np.float32(0.9494)] 
2024-11-08 16:08:31.058407: Epoch time: 359.39 s 
2024-11-08 16:08:31.058487: Yayy! New best EMA pseudo Dice: 0.9318000078201294 
2024-11-08 16:08:34.541117:  
2024-11-08 16:08:34.541586: Epoch 49 
2024-11-08 16:08:34.541754: Current learning rate: 0.00217 
2024-11-08 16:14:33.956523: train_loss -0.8466 
2024-11-08 16:14:33.957127: val_loss -0.8646 
2024-11-08 16:14:33.957392: Pseudo dice [np.float32(0.9393), np.float32(0.9174), np.float32(0.9518)] 
2024-11-08 16:14:33.957595: Epoch time: 359.42 s 
2024-11-08 16:14:34.664891: Yayy! New best EMA pseudo Dice: 0.9322999715805054 
2024-11-08 16:14:38.268778:  
2024-11-08 16:14:38.269231: Epoch 50 
2024-11-08 16:14:38.269624: Current learning rate: 0.00199 
2024-11-08 16:20:37.767130: train_loss -0.848 
2024-11-08 16:20:37.767451: val_loss -0.8625 
2024-11-08 16:20:37.767786: Pseudo dice [np.float32(0.9374), np.float32(0.9166), np.float32(0.9505)] 
2024-11-08 16:20:37.767955: Epoch time: 359.5 s 
2024-11-08 16:20:37.768083: Yayy! New best EMA pseudo Dice: 0.9325000047683716 
2024-11-08 16:20:41.302845:  
2024-11-08 16:20:41.303086: Epoch 51 
2024-11-08 16:20:41.303344: Current learning rate: 0.00181 
2024-11-08 16:26:40.641810: train_loss -0.8472 
2024-11-08 16:26:40.642306: val_loss -0.8598 
2024-11-08 16:26:40.642670: Pseudo dice [np.float32(0.9368), np.float32(0.9182), np.float32(0.9463)] 
2024-11-08 16:26:40.642795: Epoch time: 359.34 s 
2024-11-08 16:26:40.642928: Yayy! New best EMA pseudo Dice: 0.932699978351593 
2024-11-08 16:26:44.292463:  
2024-11-08 16:26:44.293031: Epoch 52 
2024-11-08 16:26:44.293212: Current learning rate: 0.00163 
2024-11-08 16:32:43.507494: train_loss -0.8479 
2024-11-08 16:32:43.508176: val_loss -0.8593 
2024-11-08 16:32:43.508340: Pseudo dice [np.float32(0.9368), np.float32(0.9152), np.float32(0.9494)] 
2024-11-08 16:32:43.508515: Epoch time: 359.22 s 
2024-11-08 16:32:43.508621: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2024-11-08 16:32:46.995373:  
2024-11-08 16:32:46.995678: Epoch 53 
2024-11-08 16:32:46.995888: Current learning rate: 0.00145 
2024-11-08 16:38:46.743456: train_loss -0.8475 
2024-11-08 16:38:46.744071: val_loss -0.8715 
2024-11-08 16:38:46.744213: Pseudo dice [np.float32(0.943), np.float32(0.9273), np.float32(0.9518)] 
2024-11-08 16:38:46.744368: Epoch time: 359.75 s 
2024-11-08 16:38:46.744458: Yayy! New best EMA pseudo Dice: 0.9336000084877014 
2024-11-08 16:38:50.260897:  
2024-11-08 16:38:50.261302: Epoch 54 
2024-11-08 16:38:50.261539: Current learning rate: 0.00126 
2024-11-08 16:44:59.556016: train_loss -0.8509 
2024-11-08 16:44:59.556447: val_loss -0.8617 
2024-11-08 16:44:59.556569: Pseudo dice [np.float32(0.9372), np.float32(0.9183), np.float32(0.9503)] 
2024-11-08 16:44:59.556799: Epoch time: 369.3 s 
2024-11-08 16:44:59.556949: Yayy! New best EMA pseudo Dice: 0.9337000250816345 
2024-11-08 16:45:03.043301:  
2024-11-08 16:45:03.043656: Epoch 55 
2024-11-08 16:45:03.043831: Current learning rate: 0.00107 
2024-11-08 16:51:13.478564: train_loss -0.8506 
2024-11-08 16:51:13.478991: val_loss -0.8698 
2024-11-08 16:51:13.479161: Pseudo dice [np.float32(0.9425), np.float32(0.9277), np.float32(0.9526)] 
2024-11-08 16:51:13.479318: Epoch time: 370.44 s 
2024-11-08 16:51:13.479428: Yayy! New best EMA pseudo Dice: 0.934499979019165 
2024-11-08 16:51:17.441467:  
2024-11-08 16:51:17.441948: Epoch 56 
2024-11-08 16:51:17.442184: Current learning rate: 0.00087 
2024-11-08 16:57:28.268404: train_loss -0.8493 
2024-11-08 16:57:28.268753: val_loss -0.8604 
2024-11-08 16:57:28.268936: Pseudo dice [np.float32(0.9368), np.float32(0.9199), np.float32(0.9449)] 
2024-11-08 16:57:28.269051: Epoch time: 370.83 s 
2024-11-08 16:57:29.676836:  
2024-11-08 16:57:29.677222: Epoch 57 
2024-11-08 16:57:29.677403: Current learning rate: 0.00067 
2024-11-08 17:03:35.675133: train_loss -0.8511 
2024-11-08 17:03:35.675600: val_loss -0.8662 
2024-11-08 17:03:35.675998: Pseudo dice [np.float32(0.9398), np.float32(0.9203), np.float32(0.9505)] 
2024-11-08 17:03:35.676130: Epoch time: 366.0 s 
2024-11-08 17:03:35.676227: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2024-11-08 17:03:39.253941:  
2024-11-08 17:03:39.254328: Epoch 58 
2024-11-08 17:03:39.254503: Current learning rate: 0.00047 
2024-11-08 17:09:40.149825: train_loss -0.8471 
2024-11-08 17:09:40.150371: val_loss -0.8682 
2024-11-08 17:09:40.150496: Pseudo dice [np.float32(0.9402), np.float32(0.9205), np.float32(0.9529)] 
2024-11-08 17:09:40.150612: Epoch time: 360.9 s 
2024-11-08 17:09:40.150694: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2024-11-08 17:09:43.778133:  
2024-11-08 17:09:43.778395: Epoch 59 
2024-11-08 17:09:43.778555: Current learning rate: 0.00025 
2024-11-08 17:15:44.580623: train_loss -0.848 
2024-11-08 17:15:44.581050: val_loss -0.8635 
2024-11-08 17:15:44.581239: Pseudo dice [np.float32(0.9387), np.float32(0.9189), np.float32(0.948)] 
2024-11-08 17:15:44.581374: Epoch time: 360.8 s 
2024-11-08 17:15:44.581490: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2024-11-08 17:15:48.736743: Training done. 
2024-11-08 17:15:48.752741: Using splits from existing split file: /media/tct-bii/DataHDD/abdomen_fat/nnUNet/nnUNet/nnUNet_preprocessed/Dataset699_AbdomenMR/splits_final.json 
2024-11-08 17:15:48.753125: The split file contains 5 splits. 
2024-11-08 17:15:48.753196: Desired fold for training: 0 
2024-11-08 17:15:48.753268: This split has 84 training and 21 validation cases. 
2024-11-08 17:15:48.753505: predicting subject_104_T1 
2024-11-08 17:15:48.755266: subject_104_T1, shape torch.Size([1, 55, 254, 255]), rank 0 
2024-11-08 17:16:12.594027: predicting subject_13_T1 
2024-11-08 17:16:12.598313: subject_13_T1, shape torch.Size([1, 60, 255, 255]), rank 0 
2024-11-08 17:16:25.945628: predicting subject_17_T1 
2024-11-08 17:16:25.949296: subject_17_T1, shape torch.Size([1, 70, 255, 255]), rank 0 
2024-11-08 17:16:39.316542: predicting subject_22_T1 
2024-11-08 17:16:39.319724: subject_22_T1, shape torch.Size([1, 56, 182, 242]), rank 0 
2024-11-08 17:16:46.028925: predicting subject_23_T1 
2024-11-08 17:16:46.031216: subject_23_T1, shape torch.Size([1, 56, 182, 243]), rank 0 
2024-11-08 17:16:52.815803: predicting subject_28_T1 
2024-11-08 17:16:52.818360: subject_28_T1, shape torch.Size([1, 56, 173, 230]), rank 0 
2024-11-08 17:16:59.533865: predicting subject_35_T1 
2024-11-08 17:16:59.537999: subject_35_T1, shape torch.Size([1, 55, 173, 230]), rank 0 
2024-11-08 17:17:06.388543: predicting subject_39_T1 
2024-11-08 17:17:06.391064: subject_39_T1, shape torch.Size([1, 53, 173, 230]), rank 0 
2024-11-08 17:17:13.099279: predicting subject_40_T1 
2024-11-08 17:17:13.102113: subject_40_T1, shape torch.Size([1, 53, 173, 230]), rank 0 
2024-11-08 17:17:19.840714: predicting subject_41_T1 
2024-11-08 17:17:19.843510: subject_41_T1, shape torch.Size([1, 53, 173, 230]), rank 0 
2024-11-08 17:17:26.577857: predicting subject_45_T1 
2024-11-08 17:17:26.580481: subject_45_T1, shape torch.Size([1, 59, 173, 230]), rank 0 
2024-11-08 17:17:33.402285: predicting subject_48_T1 
2024-11-08 17:17:33.404694: subject_48_T1, shape torch.Size([1, 53, 182, 243]), rank 0 
2024-11-08 17:17:40.117034: predicting subject_49_T1 
2024-11-08 17:17:40.119272: subject_49_T1, shape torch.Size([1, 53, 182, 242]), rank 0 
2024-11-08 17:17:46.889332: predicting subject_54_T1 
2024-11-08 17:17:46.891466: subject_54_T1, shape torch.Size([1, 56, 158, 230]), rank 0 
2024-11-08 17:17:53.668597: predicting subject_58_T1 
2024-11-08 17:17:53.670626: subject_58_T1, shape torch.Size([1, 75, 256, 256]), rank 0 
2024-11-08 17:18:13.879094: predicting subject_61_T1 
2024-11-08 17:18:13.881449: subject_61_T1, shape torch.Size([1, 57, 256, 256]), rank 0 
2024-11-08 17:18:27.330788: predicting subject_70_T1 
2024-11-08 17:18:27.333424: subject_70_T1, shape torch.Size([1, 60, 255, 255]), rank 0 
2024-11-08 17:18:40.894468: predicting subject_74_T1 
2024-11-08 17:18:40.896824: subject_74_T1, shape torch.Size([1, 67, 255, 255]), rank 0 
2024-11-08 17:18:54.306215: predicting subject_76_T1 
2024-11-08 17:18:54.308429: subject_76_T1, shape torch.Size([1, 67, 256, 255]), rank 0 
2024-11-08 17:19:07.916055: predicting subject_84_T1 
2024-11-08 17:19:07.917971: subject_84_T1, shape torch.Size([1, 58, 274, 274]), rank 0 
2024-11-08 17:19:21.437050: predicting subject_86_T1 
2024-11-08 17:19:21.440697: subject_86_T1, shape torch.Size([1, 70, 255, 255]), rank 0 
2024-11-08 17:19:43.877612: Validation complete 
2024-11-08 17:19:43.877773: Mean Validation Dice:  0.9385128960726457 
